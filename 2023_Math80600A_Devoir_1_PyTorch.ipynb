{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ba0e3e8e94e4801bd737866bb219c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bf74f5121ba41768c554184ee17c47d",
              "IPY_MODEL_de995e7b3425400e86185a51eda7c2ed",
              "IPY_MODEL_278d54a61812423a893b3f597cfa8786"
            ],
            "layout": "IPY_MODEL_2a5e551ad62a4f8cb082aef7d35da8d4"
          }
        },
        "7bf74f5121ba41768c554184ee17c47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2b3469996d41f5994a212b34d10da5",
            "placeholder": "​",
            "style": "IPY_MODEL_2d54d1203bdc4cbba13df9d3e0d28432",
            "value": ""
          }
        },
        "de995e7b3425400e86185a51eda7c2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deef96b96a5e4595a2d55f975dab947c",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edf9f0c27088447baf1f5a2155ee0297",
            "value": 170498071
          }
        },
        "278d54a61812423a893b3f597cfa8786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47689731c45644f8a88e7e789959bc55",
            "placeholder": "​",
            "style": "IPY_MODEL_a0cdcf65ee0a457a9878e03985019c3b",
            "value": " 170499072/? [00:11&lt;00:00, 17219360.11it/s]"
          }
        },
        "2a5e551ad62a4f8cb082aef7d35da8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2b3469996d41f5994a212b34d10da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d54d1203bdc4cbba13df9d3e0d28432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deef96b96a5e4595a2d55f975dab947c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf9f0c27088447baf1f5a2155ee0297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47689731c45644f8a88e7e789959bc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cdcf65ee0a457a9878e03985019c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenzaChraibi/Devoir-ML2/blob/main/2023_Math80600A_Devoir_1_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_LTBtfMBvW_"
      },
      "source": [
        "# Apprentissage automatique II: Apprentissage profond et ses applications\n",
        "# Devoir 1\n",
        "\n",
        "**Date de remise:  15 février**\n",
        "\n",
        "### Instructions\n",
        "- Faites une copie de ce bloc-notes sur votre propre Google Drive et répondez aux questions qui s'y trouvent.\n",
        "- Vous pouvez ajouter plus de cellules si nécessaire. Vous pouvez également ajouter des descriptions à votre code, bien que ce ne soit pas obligatoire.\n",
        "- Assurez-vous que le bloc-notes peut être exécuté par *Exécution -> Tout exécuter*. **Dérouler toutes les cellules** afin de faciliter l'évaluation.\n",
        "- Enregistrer le lien de votre bloc-notes [ici](https://docs.google.com/forms/d/e/1FAIpQLSfcK31V4E16aSN1G26BHqcdmn2qGcPLO7RAlJRvbU_blrUz8g/viewform?usp=sharing). Veuillez **activer la modification ou les commentaires** afin que vous puissiez recevoir des commentaires des correcteur.trice.s.\n",
        "  - Ajoutez zuobai.zhang@gmail.com et jiaruilu27@gmail.com en tant qu'**éditeur** sur votre devoir de code Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33dD1e8tii2"
      },
      "source": [
        "Installation des bibliothèques Pytorch et Torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJB3VQYDCUmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2733abae-0837-488a-ac02-0c4cd9ebadfb"
      },
      "source": [
        "!pip install -q torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchtext==0.9.0 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m863.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_Dl6qxCXmv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from torchvision import transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uevQtU7NtZ_-"
      },
      "source": [
        "## 1) Opérations sur les tenseurs (30 points)\n",
        "\n",
        "Les opérations tensorielles sont importantes dans les modèles d'apprentissage profond. Dans cette partie, vous devrez implémenter certaines opérations tensorielles courantes en PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DeQOItkeQCx"
      },
      "source": [
        "### 1.1) Serrage (*squeezing*), desserrage (*unsqueezing*) et visualisage (*viewing*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAOmBE5ODwpP"
      },
      "source": [
        "Le serrage (squeezing), desserrage (unsqueezing) et visualisage (viewing) d'un tenseur sont des opérations importantes afin de changer les dimensions d'un tenseur. Comme nous l'avons vu dans le tutoriel, les fonctions de base sont [torch.squeeze](https://pytorch.org/docs/stable/torch.html#torch.squeeze), [torch.unsqueeze](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) et [torch.Tensor.view](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). Veuillez lire la documentation associée et effectuez l'exercice suivante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrM80YxFSjb"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "\n",
        "# Ajouter deux nouvelles dimensions à x en utilisant la fonction torch.unsqueeze, de façon telle à ce que les dimensions de x soient de (3,1,2,1.\n",
        "x = torch.unsqueeze(torch.unsqueeze(x,1),3)\n",
        "\n",
        "# Enlever les deux dimensions précédemment ajoutées en utilisant la fonction torch.squeeze de façon telle à retrouver les dimensions d'origine.\n",
        "x = torch.squeeze(x)\n",
        "\n",
        "# Utilisez la fonction torch.Tensor.view afin de transformer le tenseur en deux dimensions en un tenseur d'une unique dimension et de longeur 6.\n",
        "x = x.view(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liuR-U0wea0n"
      },
      "source": [
        "### 1.2) Concaténation et empilage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkbnt6v8Bo-j"
      },
      "source": [
        "La concaténation et l'empilage de tenseurs sont des opérations permettant de combiner de petits tenseurs en grands tenseurs.\n",
        "\n",
        "Les fonctions correspondantes sont [torch.cat](https://pytorch.org/docs/stable/torch.html#torch.cat) et [torch.stack](https://pytorch.org/docs/stable/torch.html#torch.stack). Veuillez lire la documentation associée et effectuez l'exercice suivante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9KqXu3Stfjh"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# y est un tenseur ayant pour dimension (3, 2)\n",
        "y = torch.Tensor([[-1, -2], [-3, -4], [-5, -6]])\n",
        "\n",
        "\n",
        "# Nous voulons créer un tenseur z de dimensions (2, 3, 2) tel que z[0,:,:] = x et z[1,:,:] = y.\n",
        "\n",
        "# Utilisez torch.stack pour créer pareil tenseur\n",
        "z = torch.stack((x,y),0)\n",
        "# Utilisez torch.cat et torch.unsqueeze pour créer pareil tenseur\n",
        "z = torch.cat((torch.unsqueeze(x,0), torch.unsqueeze(y,0)),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGw4eEo-eeHm"
      },
      "source": [
        "### 1.3) Expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAII9eJgJFK2"
      },
      "source": [
        "L'expansion d'un tenseur consiste à étendre un tenseur en un tenseur plus grand le long des dimensions du singleton. Les fonctions correspondantes sont [torch.Tensor.expand](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand) et [torch.Tensor.expand_as](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as). Veuillez lire la documentation associée et effectuez l'exercice suivante.\n",
        "\n",
        "\n",
        "Enfin, expliquez sous forme de commentaire en une ou deux phrases MAXIMUM quelles sont les différences entre les fonctions suivantes:\n",
        "\n",
        "```\n",
        "torch.Tensor.view()\n",
        "torch.Tensor.expand()\n",
        "torch.Tensor.reshape()\n",
        "torch.Tensor.repeat()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbFte-AJzVL"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3)\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "\n",
        "# Nous voulons créer un tenseur z de dimensions (2, 3) tel que z[0,:] = x, z[1,:] = x.\n",
        "\n",
        "# Changez la dimension de x en un tenseur de dimension (1, 3) à l'aide de torch.unsqueeze\n",
        "x = torch.unsqueeze(x,0)\n",
        "# Déroulez ensuite le nouveau tenseur au tenseur cible en utilisant torch.Tensor.expand.\n",
        "z = x.expand(2,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Réponse théorique à la question 1.3)**\n",
        "\n",
        "Torch.Tensor.view permet de changer visuellement (view) les dimensions d'un tensor tout en conservant les données et le nombre d'éléments inchangés (exemple de [3,2] à [6]), mais les données sont toujours écrites de la même façon dans la mémoire alors que Torch.Tensor.reshape fait exactement la même chose, mais pourrait changer ce qui est écrit dans la mémoire en faisant une copie au lieu d'une vue si les transformations demandées le rendent nécessaire (non-contiguous storage). \n",
        "\n",
        "Torch.Tensor.expand permet d'augmenter les dimensions de 1 en des dimensions plus grandes en dupliquant le tensor dans la direction concernée, mais sans changer les dimensions différentes de 1 (exemple [3,1] en [3,2]) alors que Torch.Tensor.repeat permet de répéter un tensor un nombre donné de fois dans les directions voulues, peu importe la dimension initiale."
      ],
      "metadata": {
        "id": "_AdFnPbuiRNQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFL_Shoef3m"
      },
      "source": [
        "### 1.4) Réduction pour une dimension choisie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEoJVw0LL9H"
      },
      "source": [
        "En apprentissage profond, nous avons souvent besoin de calculer la valeur moyenne/somme/max/min dans une dimension donnée d'un tenseur. Veuillez vous référer [torch.mean](https://pytorch.org/docs/stable/torch.html#torch.mean), [torch.sum](https://pytorch.org/docs/stable/torch.html#torch.sum), [torch.max](https://pytorch.org/docs/stable/torch.html#torch.max), [torch.min](https://pytorch.org/docs/stable/torch.html#torch.min), [torch.topk](https://pytorch.org/docs/stable/torch.html#torch.topk) et complétez le code ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dlZwe4MNxo"
      },
      "source": [
        "# x est un tenseur de dimension (10, 50)\n",
        "x = torch.randn(10, 50)\n",
        "\n",
        "# Calculez la valeur moyenne pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_mean de taille (10), où x_mean[k] est la valeur moyenne de la k-ième ligne de x.\n",
        "x_mean = torch.mean(x,1)\n",
        "# Calculer la valeur somme pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_sum de taille (10).\n",
        "x_sum = torch.sum(x,1)\n",
        "# Calculez la valeur maximale pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_max de taille (10).\n",
        "x_max = torch.max(x,1)[0]\n",
        "# Calculez la valeur min pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_min de taille (10).\n",
        "x_min = torch.min(x,1)[0]\n",
        "# Calculez les 5 plus grandes valeurs pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_top de taille (10, 5), où x_top[k, :] est les 5 plus grandes valeurs de la k-ième ligne de x.\n",
        "x_top = torch.topk(x,5,1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-bmI72yr7Gm"
      },
      "source": [
        "### 1.5) Opérations avancées\n",
        "\n",
        "En apprentissage profond, nous souhaitons souvent ne modifier qu'une partie d'un tenseur ou ne collecter que des valeurs à partir d'indices spécifiques. A ces fins, on utilise souvent ```torch.gather``` ou ```torch.scatter```, voir leur définition [ici](https://pytorch.org/docs/stable/tensors.html?highlight=scatter#torch.Tensor.scatter). \n",
        "\n",
        "Notez que vous **n'êtes pas obligé.e.s** d'utiliser ces fonctions et que certaines parties de la question peuvent ne pas en avoir besoin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVUKcSlLtf-r"
      },
      "source": [
        "ind = torch.randint(50,(10,50))\n",
        "x = torch.randn(10,50,50)\n",
        "\n",
        "# Sélectionnez pour tout i,j les valeurs x[i,j,k] où ind[i,j] = k dans le tenseur\n",
        "# Le tenseur doit avoir la forme (10,50)\n",
        "x1 = torch.gather(x,2,ind.view(10,50,1)).view(10,50)\n",
        "# Doublez pour tout i,j les valeurs x[i,j,k] où ind[i,j] = k en laissant toutes les autres valeurs de x intactes\n",
        "# Le tenseur retourné doit avoir la forme (10,50,50)\n",
        "x2=x+0\n",
        "x2.scatter_(2,ind.view(10,50,1),2,reduce='multiply')\n",
        "\n",
        "ind = ind[:, 0]\n",
        "# Sélectionnez les valeurs de x[i,l,j] où l = ind[k] pour tous les i,j,k\n",
        "# Le tenseur retourné doit avoir la forme (10,10,50)\n",
        "x3 = torch.Tensor(10,10,50)\n",
        "for i in np.arange(0,10,1):\n",
        "  for j in np.arange(0,50,1):\n",
        "    for k in np.arange(0,10,1):\n",
        "      l = ind[k]\n",
        "      x3[i][k][j]=x[i][l][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I49qjiqHB9oa"
      },
      "source": [
        "## 2) CNNs (40 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JePbG5pSt1xv"
      },
      "source": [
        "Implémentez un CNN pour la classification d'images sur l'ensemble de données CIFAR-10.\n",
        "\n",
        "CIFAR-10 est un jeu de données d'images de 10 catégories. Chaque image a une taille de 32x32 pixels. Le code suivant téléchargera l'ensemble de données et le divisera en *train* et *test*.\n",
        "\n",
        "Pour cette question, nous divisons les données d'entrainement (80 %) et de validation (20 %) pour la sélection des hyperparamètres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnPc57fIwQj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "7ba0e3e8e94e4801bd737866bb219c53",
            "7bf74f5121ba41768c554184ee17c47d",
            "de995e7b3425400e86185a51eda7c2ed",
            "278d54a61812423a893b3f597cfa8786",
            "2a5e551ad62a4f8cb082aef7d35da8d4",
            "ce2b3469996d41f5994a212b34d10da5",
            "2d54d1203bdc4cbba13df9d3e0d28432",
            "deef96b96a5e4595a2d55f975dab947c",
            "edf9f0c27088447baf1f5a2155ee0297",
            "47689731c45644f8a88e7e789959bc55",
            "a0cdcf65ee0a457a9878e03985019c3b"
          ]
        },
        "outputId": "c1a46efb-8294-4b77-887b-da6cdd816cda"
      },
      "source": [
        "t = torchvision.transforms.ToTensor()\n",
        "train_dataset = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=t)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=t)\n",
        "\n",
        "N = len(train_dataset)\n",
        "indices = np.arange(N)\n",
        "np.random.shuffle(indices)\n",
        "n = int(0.8 * N)\n",
        "print('{} for training,\\t{} for validation'.format(n, N-n))\n",
        "train_indices = indices[:n]\n",
        "valid_indices = indices[n:]\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
        "\n",
        "# Entrainement du modele\n",
        "# NE PAS MODIFIER\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for X, y in dataloader:\n",
        "        logits = model(X.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, y.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "        total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction\n",
        "\n",
        "# Évalation du modele\n",
        "# NE PAS MODIFIER\n",
        "def evaluate(model, dataloader, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            logits = model(X.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, y.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "            total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ba0e3e8e94e4801bd737866bb219c53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "40000 for training,\t10000 for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBpiwMwi6wD"
      },
      "source": [
        "Le code suivant permet de visualiser certains exemples dans l'ensemble de données. Vous pouvez l'utiliser pour déboguer votre modèle si nécessaire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzZ_UvgNwSYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4556d17f-1fb1-4c19-be44-7f90a3231d0a"
      },
      "source": [
        "def plot(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])\n",
        "\n",
        "train_dataset.labels = [train_dataset.classes[target] for target in train_dataset.targets]\n",
        "plot(train_dataset.data, train_dataset.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwzKmdcuCv1D"
      },
      "source": [
        "### 2.1) Rudiments pour l'implémentation d'un CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEYo5WgjTtm"
      },
      "source": [
        "Soit un CNN vanille constitué de:\n",
        "\n",
        "- Trois couches de convolutions suivie d'une couche linéaire tel que vue lors de la troisième semaine.\n",
        "- Chaque couche de convolution est associée à un noyau de dimension 3, avec une marge de de zéros de dimension 1.\n",
        "- Une fonction d'activation ReLU après chaque couche cachée..\n",
        "\n",
        "Veuillez implémenter ce modèle dans la section suivante. Vous devrez ajuster les hyperparamètres et remplir les résultats dans le tableau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKyE2GUfL-Z"
      },
      "source": [
        "#### a) Implémentation des couches de convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_aYytExtq9"
      },
      "source": [
        "\n",
        "Implémentez la fonction d'initialisation et la fonction de transfert du CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDmCKUD1LBFk"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, cancv1, cancv2, cancv3):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, cancv1, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(cancv1, cancv2, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(cancv2, cancv3, 3, padding=1)\n",
        "    self.fc = nn.Linear(32 * 32 * cancv3, 10)\n",
        "    # initialisation des paramètres ici\n",
        "  \n",
        "  def forward(self, images):\n",
        "    images = F.relu(self.conv1(images))\n",
        "    images = F.relu(self.conv2(images))\n",
        "    images = F.relu(self.conv3(images))\n",
        "    images = torch.flatten(images, 1)\n",
        "    images = self.fc(images)\n",
        "    # implémentation de la fonction forward ici\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_YaASPpgRiL"
      },
      "source": [
        "#### b) Sélection d'hyper paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygMcDdpy6XWP"
      },
      "source": [
        "Entraînez le modèle CNN sur l'ensemble de données CIFAR-10. Sélectionnez le nombre de canaux (ou *feature maps*), l'optimiseur, le pas d'apprentissage et le nombre d'époques pour une meilleure précision de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezqosnJbwUGC"
      },
      "source": [
        "# Sélectionnez le type d'optimiseur et les hyperparamètres avec le code suivant comme exemple\n",
        "batch_size = 128\n",
        "\n",
        "### Hyperparamètres à modifier ###\n",
        "EPOCHS = 20\n",
        "cancv1 = 512; cancv2 = 512; cancv3 = 512\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for lr in [1e-4, 5e-4, 1e-3, 5e-3]:\n",
        "  print('lr : ', lr)\n",
        "  # Initialisation du modèle\n",
        "  model = CNN(cancv1, cancv2, cancv3)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.cuda()\n",
        "\n",
        "  # Apprentissage et phase de test\n",
        "  # Vous pouvez réutiliser le bloc de codage suivant pour le réglage des hyperparamètres\n",
        "  # N'hésitez pas à essayer des stratégies d'entraînement plus avancées\n",
        "  best_valid_acc = 0.0\n",
        "  best_epoch = 0\n",
        "  best_state_dict = copy.deepcopy(model.state_dict())\n",
        "  for epoch in range(EPOCHS):\n",
        "      train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "      valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "      print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          best_state_dict = copy.deepcopy(model.state_dict())\n",
        "          best_epoch = epoch + 1\n",
        "  print(best_valid_acc, best_epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EHKzozkRbD"
      },
      "source": [
        "Notez les **performances de validation** de votre modèle sous différents paramètres d'hyperparamètres.\n",
        "\n",
        "**Indice:** Vous aurez peut-être besoin de plus d'époques pour SGD qu'Adam.\n",
        "\n",
        "**Réponse**: La performance enregistrée est en terme de valid_acc pour la meilleure combinaison (lr, EPOCHS)\n",
        "\n",
        "| #Canaux par couche \\ optimiseur | SGD (lr, epochs)| Adam (lr, epochs)|\n",
        "|---------------------------------|-----------------|------------------|\n",
        "| (128, 128, 128)                 | 0.502 (1e-3, 46)| 0.679 (5e-4, 6)  |\n",
        "| (256, 256, 256)                 | 0.641 (5e-3, 47)| 0.673 (1e-4, 6)  |\n",
        "| (512, 512, 512)                 | 0.642 (5e-3, 37)| 0.671 (1e-4, 6)  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qde4aq1_2UJb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go55LVSJd-vG"
      },
      "source": [
        "### 2.2) Implémentation d'un CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G0eCj6OmOEE"
      },
      "source": [
        "Sur la base du CNN de la question précédente, implémentez un CNN complet avec une couche de *max pooling*.\n",
        "\n",
        "- Ajoutez une couche de *max pooling* après chaque couche de convolution.\n",
        "- Chaque couche de *max pooling* a une taille de noyau de 2 et une foulée (*stride*) de 2.\n",
        "\n",
        "Veuillez implémenter ce modèle dans la section suivante. Vous devrez ajuster les hyperparamètres et remplir les résultats dans le tableau. Vous devez également répondre aux questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMrKGlMQhCa0"
      },
      "source": [
        "#### a) CNN avec fonction de *max pooling*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2INt6P3Myd1"
      },
      "source": [
        "Copiez l'implémentation CNN dans la question précédente et initialisez les couches de *max pooling*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu3Ic2dM1S9"
      },
      "source": [
        "class CNN_MaxPool(nn.Module):\n",
        "  def __init__(self, cancv1, cancv2, cancv3):\n",
        "    super(CNN_MaxPool, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, cancv1, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(cancv1, cancv2, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(cancv2, cancv3, 3, padding=1)\n",
        "    self.maxp = nn.MaxPool2d(2,2)\n",
        "    self.fc = nn.Linear(4 * 4 * cancv3, 10)\n",
        "    # initialisation des paramètres ici\n",
        "  \n",
        "  def forward(self, images):\n",
        "    images = self.maxp(F.relu(self.conv1(images)))\n",
        "    images = self.maxp(F.relu(self.conv2(images)))\n",
        "    images = self.maxp(F.relu(self.conv3(images)))\n",
        "    images = torch.flatten(images, 1)\n",
        "    images = self.fc(images)\n",
        "    # implémentez la fonction forward ici\n",
        "    return images"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6AEOoigq68"
      },
      "source": [
        "#### b) Sélection d'hyper paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drH4MHSVNqwz"
      },
      "source": [
        "Sur la base du meilleur optimiseur que vous avez trouvé dans le problème précédent, choisissez le nombre de canaux et le pas d'apprentissage pour une meilleure formance de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgRRWGjnwWj-"
      },
      "source": [
        "# initialisation des hyper paramètres ici\n",
        "batch_size = 128\n",
        "\n",
        "### Hyperparamètres à modifier ###\n",
        "EPOCHS = 40\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# entraînement du modèle là\n",
        "for cancv1, cancv2, cancv3 in [(64, 64, 64), (128, 128, 128), (128, 256, 512), \n",
        "                               (256, 256, 256), (256, 512, 1024), \n",
        "                               (512, 512, 512), (512, 1024, 2048)]:\n",
        "  for lr in [1e-4, 5e-4]:\n",
        "    print('lr : ', lr, 'canaux :', cancv1, cancv2, cancv3)\n",
        "    # Initialisation du modèle\n",
        "    model = CNN_MaxPool(cancv1, cancv2, cancv3)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.cuda()\n",
        "\n",
        "    # Apprentissage\n",
        "    best_valid_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "        valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "        print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "        if valid_acc > best_valid_acc:\n",
        "            best_valid_acc = valid_acc\n",
        "            best_state_dict = copy.deepcopy(model.state_dict())\n",
        "            best_epoch = epoch + 1\n",
        "    print(best_valid_acc, best_epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Mu2ZZHoZU0"
      },
      "source": [
        "Notez la **précision de validation** de votre modèle sous différents paramètres et hyperparamètres.\n",
        "\n",
        "**Réponse**: La performance enregistrée est en terme de valid_acc pour la meilleure combinaison (lr, EPOCHS) et l'optimiseur Adam (le plus performant selon les résultats en 2.1-b).\n",
        "\n",
        "| #Canaux pour chaque couche | Performance de validation (lr, EPOCHS)|\n",
        "|----------------------------|---------------------------------------|\n",
        "| (64, 64, 64)               |    0.719 (5e-4, 33)                   |\n",
        "| (128, 128, 128)            |    0.731 (5e-4, 20)                   |\n",
        "| (128, 256, 512)            |    0.747 (5e-4, 14)                   |\n",
        "| (256, 256, 256)            |    0.746 (5e-4, 17)                   |\n",
        "| (256, 512, 1024)           |    0.752 (5e-4, 13)                   |\n",
        "| (512, 512, 512)            |    0.749 (5e-4, 10)                   |\n",
        "| (512, 1024, 2048)          |    0.778 (1e-4, 28)                   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UCaz8nWoWWS"
      },
      "source": [
        "Pour le meilleur modèle obtenue, testez-le sur l'ensemble de test.\n",
        "\n",
        "Aucun souci si vous avez trouvé une combinaison d'hyperparamètres meilleure que celles répertoriées dans les tableaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtidyfEvzEG1"
      },
      "source": [
        "# Évaluez le modèle ici\n",
        "# Entraînez le modèle sur l'ensemble d'entraînement\n",
        "# Trouvez le meilleur modèle/hyperparamètre avec l'ensemble de validation\n",
        "\n",
        "# initialisation des données\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialisation du modèle\n",
        "cancv1 = 512; cancv2 = 1024; cancv3 = 2048\n",
        "lr = 1e-4\n",
        "EPOCHS = 28\n",
        "model = CNN_MaxPool(cancv1, cancv2, cancv3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "\n",
        "# Apprentissage\n",
        "best_valid_acc = 0.0\n",
        "best_epoch = 0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        best_epoch = epoch + 1\n",
        "    if best_valid_acc >= 0.778:\n",
        "       break\n",
        "print(best_valid_acc, best_epoch)\n",
        "\n",
        "# Appliquez ce meilleur modèle sur l'ensemble de test\n",
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSbhC8f1or6_"
      },
      "source": [
        "Quel est la **performance sur l'ensemble test** obtenue?\n",
        "\n",
        "**Votre réponse:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3E9ZckomkX"
      },
      "source": [
        "Que pouvez-vous conclure pour la conception d'architectures d'un CNN ?\n",
        "\n",
        "**Votre réponse:**\n",
        "\n",
        "De manière générale, peu importe l'architecture choisie, l'optimiseur Adam semble mieux performer et être plus rapide (moins d'epochs nécessaires) que l'optimiseur SGD. Il a aussi besoin d'un taux d'apprentissage (lr) plus petit. \n",
        "\n",
        "Ensuite, avec Adam, on remarque facilement que l'ajout de la couche de pooling après chaque convolution améliore les performances pour une même architecture, mais augmente également le nombre d'itérations nécessaires (epochs). Pour des réseaux de profondeur égale, l'augmentation de la largeur des couches (nombre de canaux) améliore elle aussi les performances. Les plus grandes architectures convergent plus rapidemment vers leur taux de performance optimal en validation et semblent par le fait même commencer à sur-apprendre plus vite que les petites, ce qui est normal, car ce sont des modèles de plus grande capacité. Cependant, elles sont beaucoup plus longues à entraîner. Finalement, le fait de garder une largeur constante à travers les différentes couches n'est pas vraiment différent du fait d'augmenter progressivement la largeur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWO5rjXuPIH5"
      },
      "source": [
        "## 3) RNNs (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2AmIPwBJt9j"
      },
      "source": [
        "Utilisons PyTorch pour implémenter un RNN pour l'analyse des sentiments, c'est-à-dire classer les phrases sous l'une des trois catégories de sentiment, soit compris positifs, négatifs ou neutres.\n",
        "\n",
        "Nous utilisons un ensemble de données de référence (c'est-à-dire SST) pour cette tâche. Tout d'abord, téléchargeons l'ensemble de données SST et effectuons un prétraitement pour créer un vocabulaire et diviser l'ensemble de données en ensembles d'apprentissage/validation/test. Définissons également la fonction d'entraînement et d'évaluation. Veuillez ne pas modifier les fonctions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8b2nr7Kq73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a11433-dbc9-4dec-e669-2478d4a50ca6"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# telecharger les donnees et les diviser en sous ensembles\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "# construction d'un dictionnaire\n",
        "TEXT.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "label_size = len(LABEL.vocab)\n",
        "padding_idx = TEXT.vocab.stoi['<pad>']\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "\n",
        "# construction des iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size=32)\n",
        "\n",
        "# Apprentissage\n",
        "# NE PAS MODIFIER\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.text.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, batch.label.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "        total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction\n",
        "\n",
        "# Evaluation\n",
        "# NE PAS MODIFIER\n",
        "def evaluate(model, iterator, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            logits = model(batch.text.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, batch.label.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "            total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading trainDevTestTrees_PTB.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:01<00:00, 560kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbWxFDZdK6rf"
      },
      "source": [
        "Ensuite, nous sommes prêts à construire notre RNN pour l'analyse des sentiments. Dans le code suivant, nous avons fourni plusieurs hyperparamètres dont nous avions besoin pour construire le modèle, y compris la taille du vocabulaire (vocab_size), la dimension d'intégration du mot (embedding_dim), la dimension de la couche cachée (hidden_dim), le nombre de couches (num_layers) et le nombre de catégories de phrases (label_size). Veuillez compléter le code  et implémenter un modèle RNN après avoir lu les instructions du dernier  [blocs](https://colab.research.google.com/drive/1D_ERWxDEFDKH92KjPVpL3dVObpiOIMqF#scrollTo=PbqSAz90zBYi)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUKPgDGNQSr"
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size, padding_idx):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.label_size = label_size\n",
        "        self.num_layers = 1\n",
        "\n",
        "        # Ajoutez les couches requises pour l'analyse des sentiments.\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=padding_idx)\n",
        "        self.rnn_cell = nn.RNN(self.embedding_dim, self.hidden_dim, self.num_layers, \n",
        "                               batch_first=True, nonlinearity='relu')\n",
        "        self.fc = nn.Linear(self.hidden_dim, self.label_size)\n",
        "        self.sm = nn.Softmax(dim=-1)\n",
        "\n",
        "    def zero_state(self, batch_size): \n",
        "        # Implémente la fonction qui renvoie un état caché initial.\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim, device='cuda')\n",
        "\n",
        "    def forward(self, text):\n",
        "        # Implémenter la fonction forward du modèle.\n",
        "        embedding = self.embedding(text) #batch, time_steps, embedding_dim\n",
        "        h0 = self.zero_state(text.size()[0])\n",
        "        out, hn = self.rnn_cell(embedding, h0)\n",
        "        output = self.sm(self.fc(torch.squeeze(hn)))\n",
        "        return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBX_xc9MN0gw"
      },
      "source": [
        "Enfin, nous sommes prêts à entraîner le modèle et à calculer ses performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrU0wuUOIgb"
      },
      "source": [
        "# Sélectionnez le type d'optimiseur et les hyperparamètres avec le code suivant comme exemple\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "EPOCHS = 30\n",
        "\n",
        "# Initialisation du modèle\n",
        "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "# Entraînement et test du modèle\n",
        "# Vous pouvez réutiliser le bloc de codage suivant pour la sélection des hyperparamètres\n",
        "# N'hésitez pas à essayer des stratégies d'entraînement plus avancées\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgT69I1reZ4"
      },
      "source": [
        "Une fois que nous avons trouvé les meilleurs hyperparamètres pour l'ensemble de validation, nous pouvons maintenant évaluer notre modèle sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDvglccrdWt"
      },
      "source": [
        "# Évaluez le modèle ici\n",
        "# Entraînez le modèle sur l'ensemble d'apprentissage\n",
        "# Trouvez le meilleur modèle/hyperparamètre avec l'ensemble de validation et calculer ses performances sur l'ensemble de test\n",
        "\n",
        "# Initialisation du modèle\n",
        "batch_size = 128\n",
        "lr = 0.1\n",
        "EPOCHS = 30\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "\n",
        "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "# Entraînement\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbqSAz90zBYi"
      },
      "source": [
        "### 3.1) Implémentation d'un RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5KEDzgzVxT"
      },
      "source": [
        "Le code actuel du modèle RNN n'est pas complet, complétons donc d'abord le code pour implémenter un modèle RNN vanille en remplissant le [bloc](https://colab.research.google.com/drive/1xNVJEYUxebI9xSA86AAjjtzVpUDUWuaF?authuser=3#scrollTo=kWUKPgDGNQSr)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiDCl9J0zIKO"
      },
      "source": [
        "- **Sous-tâche 1-1: Création de toutes les couches requises dans votre modèle**\n",
        "\n",
        "N'oubliez pas que lors de la construction d'un modèle d'apprentissage profond, nous devons d'abord compléter la fonction **init** en créant toutes les couches requises. Dans notre cas, puisque nous utilisons des RNNs pour la classification des phrases, nous avons besoin d'une couche d'intégration (*embedding*) pour transformer les mots en intégrations (*embedding*) de mots, d'une couche RNN pour transformer les intégrations (*embedding*) de mots en codages de phrases, d'une fonction d'activation et d'une couche linéaire ainsi que d'une fonction softmax pour le classement des phrases.\n",
        "\n",
        "Ceci étant, veuillez créer toutes les couches nécessaires de votre modèle RNN dans la fonction **init**. Notez que nous avons déjà ajouté la couche d'intégration de mots pour vous."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF_dE-TqzL0A"
      },
      "source": [
        "- **Sous-tâche 1-2: Implémentation de la fonction d'initialisation des états cachés**\n",
        "\n",
        "Rappelez-vous que lors de l'application d'une unité RNN pour transformer des intégrations (*embedding*) de mots en codages de phrases, l'unité RNN part d'un vecteur caché initial avec toutes les valeurs nulles et lit séquentiellement chaque mot pour mettre à jour le vecteur caché. Enfin, le vecteur caché obtenu après lecture du dernier mot est traité comme l'encodage de la phrase.\n",
        "\n",
        "Veuillez implémenter la fonction **zero_state**, qui renvoie un lot de vecteurs cachés initiaux en fonction d'une taille de lot (*batch*). Astuce : votre fonction doit renvoyer un tenseur avec toutes les valeurs nulles. Vous pouvez vous référer au [document officiel](https://pytorch.org/docs/stable/nn.html#rnn) pour définir les dimensions adéquates pour le tenseur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiPTOnY28Iq"
      },
      "source": [
        "- **Sous-tâche 1-3: Implémentation de la fonction forward**\n",
        "\n",
        "Enfin, nous sommes prêts à construire la fonction *forward*, qui prend un lot de phrases en entrée et renvoie un lot de logits. Pour être plus précis, l'entrée est donnée par le tenseur appelé $\\text{text}$, et la taille du tenseur est $(B, L)$, $B$ étant la taille du lot, $L$ étant la longueur maximale des phrases dans ce lot et $\\text{text}[i, j]$ étant l'identifiant entier du $j$-ème mot dans la $i$-ème phrase. Étant donné le tenseur en entrée, votre fonction  doit renvoyer un tenseur logit de taille $(B, C)$, $B$ étant la taille du lot et $C$ étant le nombre de classes possibles.\n",
        "\n",
        "Veuillez implémenter la fonction de *forward* en fonction des instructions ci-dessus. Notez que nous avons déjà appliqué la couche d'intégration de mots à l'entrée de texte et obtenu un tenseur appelé $\\text{embedding}$, et la taille du tenseur est $(B, L, D)$, où $D$ est le mot dimension d'intégration. Vous pouvez directement opérer sur le tenseur $\\text{embedding}$ pour calculer les logits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUL9zYw4y_IZ"
      },
      "source": [
        "### 3.2) Étude des différents optimiseurs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKKFSkzzUA_"
      },
      "source": [
        "Lors de la tâche précédente, nous avons implémenté un modèle RNN pour l'analyse des sentiments, ou plus généralement la classification des phrases.\n",
        "\n",
        "Pour mieux comprendre plusieurs concepts en apprentissage profond, faisons quelques études d'ablation en utilisant le modèle que nous venons d'implémenter.\n",
        "\n",
        "La première tâche consiste à essayer différents optimiseurs pour votre modèle, où pour chaque optimiseur, vous pouvez également essayer différentes valeurs de pas d'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "EPOCHS = 30\n",
        "\n",
        "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
        "  print('lr :', lr)\n",
        "  # Initialisation du modèle\n",
        "  model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "  #optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  #optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.cuda()\n",
        "  criterion.cuda()\n",
        "\n",
        "  # Entraînement et test du modèle\n",
        "  best_valid_acc = 0.0\n",
        "  best_state_dict = copy.deepcopy(model.state_dict())\n",
        "  for epoch in range(EPOCHS):\n",
        "      train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "      valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "      print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          best_state_dict = copy.deepcopy(model.state_dict())\n",
        "          best_epoch = epoch + 1\n",
        "  print(best_valid_acc, best_epoch)"
      ],
      "metadata": {
        "id": "TjjCPT-IEI4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlnDbZtqHgi"
      },
      "source": [
        "- **Sous-tâche 2-1: Remplir le tableau**\n",
        "\n",
        "Nous avons fourni le tableau suivant pour différentes combinaisons d'optimiseurs et de pas d'apprentissage. Veuillez noter la **performance de validation** de votre modèle avec différents optimiseurs et taux d'apprentissage.\n",
        "\n",
        "|         | 0.1  | 0.01 | 0.001|0.0001|\n",
        "|---------|------|------|------|------|\n",
        "| SGD     | 0.563| 0.499| 0.472| 0.388|\n",
        "| Adam    |  nan | 0.394| 0.433| 0.537|\n",
        "| RMSprop |  nan |  nan | 0.492| 0.535|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVd5b9rzSFA"
      },
      "source": [
        "- **Sous-tâche 2-2: Expliquez vos résultas**\n",
        "\n",
        "En fonction de vos résultats, expliquez BRIÈVEMENT vos observations, par exemple, quel optimiseur fonctionne le mieux, quel est le taux d'apprentissage optimal pour chaque optimiseur ?\n",
        "\n",
        "***Votre réponse:***\n",
        "\n",
        "La première observation concerne les nan présents dans le tableau. En fait, le modèle donne une performance de 0.403 en tout temps, ce qui donne l'impression qu'il n'apprend pas grand chose. Le loss quant à lui donne directement nan. De ce fait, les optimiseurs Adam et RMSprop semblent mieux fonctionner avec des petits taux d'apprentissage. Ils atteignent tous les deux leur performance maximale pour lr=0.0001, ce qui est tout de même comparable à la performance du SGD. Par contre, pour SGD, c'est le contraire. Sa performance diminue en même temps que le taux d'apprentissage. Son meilleur résultat est pour lr=0.1, ce qui correspond à la meilleure performance parmi l'ensemble des optimiseurs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyy7qpHtzYJn"
      },
      "source": [
        "### 3.3) Comparez les résultats en fonction du nombre d'époques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXQERRizZO6"
      },
      "source": [
        "Nous comparerons les résultats de notre modèle pour différents nombres d'époques d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "lr = 0.1\n",
        "\n",
        "for EPOCHS in [10, 20, 30, 40, 50]:\n",
        "  print('epochs :', EPOCHS)\n",
        "  # Initialisation du modèle\n",
        "  model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.cuda()\n",
        "  criterion.cuda()\n",
        "\n",
        "  # Entraînement et test du modèle\n",
        "  best_valid_acc = 0.0\n",
        "  best_state_dict = copy.deepcopy(model.state_dict())\n",
        "  for epoch in range(EPOCHS):\n",
        "      train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "      valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "      print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          best_state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  print(train_acc, valid_acc)"
      ],
      "metadata": {
        "id": "iA94RH62GN4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBBjTGd1zis"
      },
      "source": [
        "- **Sous-tâche 3-1: Completez le talbeau**\n",
        "\n",
        "Veuillez présenter les **performances d'entraînement et de validation** de votre modèle avec différents nombres d'époques d'entraînement dans le tableau suivant.\n",
        "\n",
        "|                           |  10  |  20  |  30  |  40  |  50  |\n",
        "|---------------------------|------|------|------|------|------|\n",
        "| Performance d'entraînement| 0.420| 0.421| 0.424| 0.434| 0.423|\n",
        "| Performance de validation | 0.397| 0.398| 0.423| 0.412| 0.403|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82_FjXazdod"
      },
      "source": [
        "- **Subtask 3-2: Répondre à la question**\n",
        "\n",
        "Est-il toujours préférable d'entraîner un modèle sur plusieurs époques ? Comment pouvons-nous décider quand arrêter l'entraînement?\n",
        "\n",
        "***Votre réponse:***\n",
        "\n",
        "Comme on peut le voir avec la performance en entraînement, plus on augmente le nombre d'epochs, plus on a globalement un meilleur résultat, ce qui est attendu puisque nous donnons à notre modèle plus de chance de comprendre les données d'entraînement pour essayer de s'y coller au mieux. Par contre, au niveau de la performance en validation, elle atteint son résultat optimal autour de 30 epochs. En effet, augmenter le nombre d'epochs mènent tout droit au phénomène de sur-apprentissage. Un nombre d'epochs trop petit peut ne pas être suffisant pour permettre au modèle de comprendre la structure des données alors qu'un nombre trop grand d'epochs peut empêcher le modèle de bien généraliser. On peut donc arrêter d'entraîner notre modèle quand on observe que la performance en validation cesse de croître pour au contraire commencer à diminuer, ce qui donne le meilleur compromis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066JcRvAze7f"
      },
      "source": [
        "### 3.4) Étude de la capacité des modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxhZpHYzjIR"
      },
      "source": [
        "En pratique, nous pouvons également faire varier la capacité de notre modèle afin de trouver le modèle optimal. Veuillez tester différentes configurations de votre modèle, lesquelles ont des capacités différentes. Sur la base de vos observations, veuillez également répondre à la question."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation du modèle\n",
        "batch_size = 128\n",
        "lr = 0.1\n",
        "EPOCHS = 30\n",
        "\n",
        "for embedding_dim in [64, 128, 256]:\n",
        "  for hidden_dim in [64, 128, 256]:\n",
        "    print('embedding_dim :', embedding_dim, 'hidden_dim :', hidden_dim)\n",
        "    model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "\n",
        "    # Entraînement\n",
        "    best_valid_acc = 0.0\n",
        "    best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "        valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "        print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "        if valid_acc > best_valid_acc:\n",
        "            best_valid_acc = valid_acc\n",
        "            best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    print(best_valid_acc)"
      ],
      "metadata": {
        "id": "z5wWUEnHHJkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fp2QC2Pzkja"
      },
      "source": [
        "- **Sous-tâche 4-1: Complétez le tableau**\n",
        "\n",
        "Veuillez noter la **performance de validation** de votre modèle pour différentes capacités de modèle (c'est-à-dire, spécifiée par les termes  *embedding dim* et *couche cachée dim*).\n",
        "\n",
        "|Embedding dim / hidden dim |  64   |  128  |  256  |\n",
        "|---------------------------|-------|-------|-------|\n",
        "| 64                        | 0.559 | 0.559 | 0.562 |\n",
        "| 128                       | 0.547 | 0.497 | 0.565 |\n",
        "| 256                       | 0.561 | 0.563 | 0.478 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY-OzP6E4JWU"
      },
      "source": [
        "- **Sous-tâche 4-2: Répondre à la question**\n",
        "\n",
        "Est-il toujours préférable d'augmenter la capacité du modèle dans ce cas? Est-il toujours préférable d'augmenter la capacité du modèle en général? Comment décider de la bonne capacité du modèle en pratique ?\n",
        "\n",
        "***Votre réponse:***\n",
        "\n",
        "Il n'est pas toujours préférable d'augmenter la capacité du modèle, car on voit clairement que le pire résultat est obtenu lorsque les deux types de capacité prennent simultanément leur plus grande valeur dans le tableau. De manière générale, le même postulat peut être posé. En effet, plus on augmente la capacité d'un modèle, plus il est en mesure de se coller parfaitement aux données d'entraînement, ce qui rend la généralisation beaucoup plus ardue. Par contre, le modèle doit avoir une capacité suffisante pour comprendre les données et éviter le sous-apprentissage. En pratique, le niveau de capacité à choisir dépend du nombre de données et de la complexité de la tâche à résoudre. Plus on a de données, plus on va avoir besoin d'une grande capacité pour bien les cerner. Également en pratique, on utilise souvent des techniques de régularisation pour diminuer la capacité des modèles trop complexes sans avoir à changer complètement de modèle.\n"
      ]
    }
  ]
}